# -*- coding: utf-8 -*-
"""TallerParcialML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oE50lbo5YKOMF6y4BAtLOvt6M2ymfbf4

#**Regresion Lineal**

El análisis de la regresión lineal se utiliza para predecir el valor de una variable según el valor de otra. La variable que desea predecir se denomina variable dependiente. La variable que está utilizando para predecir el valor de la otra variable se denomina variable independiente.

###**Scikit-Learn**

*Scikit-Learn* es una de estas librerías gratuitas para Python. Cuenta con algoritmos de clasificación, regresión, clustering y reducción de dimensionalidad. Además, presenta la compatibilidad con otras librerías de Python como NumPy, SciPy y matplotlib.

La gran variedad de algoritmos y utilidades de Scikit-learn la convierten en la herramienta básica para empezar a programar y estructurar los sistemas de análisis datos y modelado estadístico. Los algoritmos de Scikit-Learn se combinan y depuran con otras estructuras de datos y aplicaciones externas como Pandas o PyBrain.

*Modelo de regresión lineal Scikit-Learn:*
[enlace](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)

*Ejemplo de regresion lineal sklearn:*
[enlace](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html)



![An image](https://www.google.com/images/rss.png)

##**1. Importe de librerias:** Pandas, Numpy, Seaborn, Matplotlib

*- Adicional se importal el modelo de regresion lineal por **sklearn**.*
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""##**2. Cargue del data set:** 
Realizamos el importe de nuestro data set [*dataWineQuality*](https://raw.githubusercontent.com/corredor-john/universidadsergioarboleda/main/dataWineQuality.csv) y creamos nuestra variable ***dfWineNoNorm*** la cual tendrá toda la información de nuestro data set, pero con los datos sin normalizar. En nuestro data set la ultima columna corresponderá a nuestras variables dependientes (***Target***), de manera que las columnas hacia la izquierda serán nuestras variables dependientes (***Features***).


"""

url = 'https://raw.githubusercontent.com/jchaves1406/Machine-Learning/5606074fb1851ab52f8f88b557dbe08e439eb601/RegresionLineal/dataWineQuality.csv'
dfWineNoNorm = pd.read_csv(url)
dfWineNoNorm.head()

"""##**2.1 Visualizacion estadistica de los datos:** 

Dado que nuestro dataFrame tiene los atributos de la librería pandas podemos utilizar nuestro método estadístico ***.describe()*** para la visualización estadística de los datos. Adicional, usaremos el método ***.T*** para imprimir la transpuesta de la matriz para tener una mayor facilidad en la lectura del dataframe.
"""

dfWineNoNorm.describe().T

"""##**2.2 Variable quality:**

Esta variable muestra si nuestros datos son categóricos, es decir la calidad de nuestros datos, de manera que a valores mas altos significara mayor calidad y a valores menores una peor calidad. Para unificar los valores de nuestro dataFrame usaremos el método ***.unique()*** el cual nos permite mostrar en un vector los valores de nuestra variable quality.
"""

dfWineNoNorm['quality'].unique()

"""##**2.3 Información del dataFrame:** Tipos de datos

Para saber que tipo de datos tiene nuestro dataFrame usaremos el metodo ***.info()*** el cual mostrara el tipo de dato de cada una de nuestras variables.
"""

dfWineNoNorm.info()

"""##**2.4 Visualizacion grafica:** Dispersión par por variable

Para visualizar las graficas de dispersión usaremos la librería ***seaborn*** con el método ***.pairplot(dataFrame)*** lo que significa que nos muestre una grafica por cada par de variables (*intersección entre variables*) en la cual podremos observar la correlación entre variables.
"""

sns.pairplot(dfWineNoNorm)

"""##**3. Matriz de correlación:**

Para construir nuestra matriz de correlación normalizada de nuestro dataFrame usaremos el método de normalización de la librería pandas ***dataFrame.corr()*** la cual se encargara de realizar la normalización de nuestra matriz.
"""

MatrizCorrNoNorm = dfWineNoNorm.corr()
MatrizCorrNoNorm

"""##**3. Regresión lineal del dataFrame:**

Se ajusta nuestro dataFrame al modelo de regresión lineal, para esto separaremos nuestras ***features*** de nuestra variable ***target (quality)*** de la siguiente manera:

"""

X = dfWineNoNorm.drop('quality', axis = 1)
y = dfWineNoNorm['quality']

"""##**3.1 Entrenamiento:**

Se divide nuestro dataFrame en datos de entrenamiento y datos de prueba donde indicaremos la cantidad porcentual de datos que queremos para prueba y el restante serán datos de entrenamiento. Indicaremos a nuestro método que no seleccione muestras aleatorias usando ***shuffle = False***. Para saber la cantidad de datos para entrenamiento usaremos el método ***.shape*** en la variable de las ***features***.
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = False)
X_train.shape

"""##**3.2 Creacion del modelo:**

Se crea el objeto del modelo de regresión lineal normalizado, para esto indicaremos a nuestro objeto ***LinearRegression(normalize = True)***. A continuación, entrenaremos el modelo enviando los datos de entrenamiento tanto ***features*** como ***target*** seleccionados en el paso anterior.
"""

ModeloLRNorm = LinearRegression(normalize = True)
ModeloLRNorm.fit(X_train, y_train)

"""##**4 Comparación respecto a nuestro modelo elaborado en C++:**

A continuación realizaremos la comparativa entre los datos arrojados por nuestro modelo de C++ y el modelo de Python usando *Sci-kit learn*.

##**4.1 Predicción de los datos de entrenamiento en Python:**

Creamos una variable que contiene la predicción de nuestras ***features*** de nuestro modelo de entrenamiento en Python.
"""

y_hat_TrainPy = ModeloLRNorm.predict(X_train)

"""##**4.2 Predicción de los datos de entrenamiento en C++:**

Importaremos nuestro archivo de texto (***.txt***) creado por nuestro programa de regresión lineal en C++ el cual contiene la predicción de nuestras ***features*** del modelo de entrenamiento en C++.
"""

y_hat_TrainCpp = pd.read_csv('/content/y_Train_Hat.txt', header = None)

"""##**4.3 Gráfica comparativa modelo C++ vs modelo Python Sci-kit learn:**

Se muestra la grafica para realizar la comparativa entre el resultado de nuestra variable *quality* (***target***) entre los dos modelos:
"""

plt.figure(figsize = (15,10))
plt.scatter(y_train, y_hat_TrainPy, c = "b", label = 'Sci-Kit learn', s = 100)
plt.scatter(y_train, y_hat_TrainCpp, c = "r", label = 'Modelo C++', s = 100)
plt.ylabel('Predicción de la calidad $\hat{y_i}$')
plt.xlabel('Calidad $y_i$')
plt.legend(loc = 2)
plt.grid()
plt.show()

"""##**4.3 Funcion de costo modelo en C++:**

Importaremos nuestro archivo de texto (***.txt***) creado por nuestro programa de regresión lineal en C++ el cual contiene los valores de costo hasta llegar al coste mínimo según *n* cantidad de iteraciones (*épocas*).
"""

costo = pd.read_csv('/content/costo.txt', header = None)

"""##**4.4 Gráfica de costo del entrenamiento vs Épocas de entrenamiento (quality) en C++:**"""

fig, ax = plt.subplots(figsize = (15,8))
ax.set_xlabel("Epoch")
ax.set_ylabel(r"Costo $J(\theta)$")
ax.plot(costo)
ax.set_title("Training cost vs Epochs for multivariable Wine Quality")
plt.show()

"""##**4.5 Tabla de coeficientes $(\theta)$ modelo Python Sci-kit learn:**"""

estimatePy = pd.DataFrame(zip(X.columns, ModeloNoNorm.coef_), columns = ['features', 'theta(θ) Sklearn'])
estimatePy

"""##**4.6 Tabla de coeficientes $(\theta)$ modelo C++:**"""

thetaOutCpp = pd.read_csv('/content/thetaOut.txt', header = None)
estimateCpp = pd.DataFrame(zip(X.columns, thetaOutCpp[0]), columns = ['features', 'theta(θ) C++'])
estimateCpp